{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grammar Miner Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation Setup\n",
    "\n",
    "The evaluation of mining input grammar from string inclusion check and grammar mining from dynamic taints are based on 2 question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "Our first question concerns the accuracy of the generated grammars which means, does our mined grammars from both techniques represent strings that would be rejected by our target program? In order to answer this question, we use the grammars produced by the two techniques as *producers*. that is, we start with the start symbol and continuously expand nonterminals according to grammar rules, then the resulting string would be fed into the target program which would either accept or reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Completeness\n",
    "\n",
    "The next question concerns the completeness of the generated grammars which basically means to what extent does the generated grammars not contain strings that would be accepted by the test subject? In order to verify this, we used a reference grammar as a producer which would create arbitrary strings which would then be parsed by the generated grammars. \n",
    "A 100% completeness indicates that the mined grammar holds all inputs of the reference grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation Subject\n",
    "\n",
    "The evluation subject in this presentation will be based on;\n",
    "1. Python url parser [urllib/parse.py](https://github.com/python/cpython/blob/3.7/Lib/urllib/parse.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reference Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "REFERENCE_URL_GRAMMAR = {\n",
    "    \"<start>\" : [\n",
    "        \"<url>\"\n",
    "    ],\n",
    "    \"<url>\" : [\n",
    "      \"<scheme>://<authority><path><query>\"  \n",
    "    ],\n",
    "    \"<scheme>\": [\n",
    "        \"http\",\n",
    "        \"https\",\n",
    "        \"ftp\",\n",
    "        \"ftps\"      \n",
    "    ],\n",
    "    \"<authority>\": [\n",
    "        \"<host>\",\n",
    "        \"<host>:<port>\",\n",
    "        \"<userinfo>@<host>\",\n",
    "        \"<userinfo>@<host>:<port>\"\n",
    "    ],\n",
    "    \"<user>\": [\n",
    "        \"user1\",\n",
    "        \"user2\",\n",
    "        \"user3\",\n",
    "        \"user4\",\n",
    "        \"user5\"\n",
    "    ],\n",
    "    \"<pass>\": [\n",
    "        \"pass1\",\n",
    "        \"pass2\",\n",
    "        \"pass3\",\n",
    "        \"pass4\",\n",
    "        \"pass5\"\n",
    "    ],\n",
    "    \"<host>\": [\n",
    "        \"host1\",\n",
    "        \"host2\",\n",
    "        \"host3\",\n",
    "        \"host4\",\n",
    "        \"host5\"\n",
    "    ],\n",
    "    \"<port>\": [\n",
    "        \"<nat>\"\n",
    "    ],\n",
    "    \"<nat>\": [\n",
    "        \"10\",\n",
    "        \"20\",\n",
    "        \"30\",\n",
    "        \"40\",\n",
    "        \"50\"\n",
    "    ],\n",
    "    \"<userinfo>\": [\n",
    "        \"<user>:<pass>\"\n",
    "    ],\n",
    "    \"<path>\": [\n",
    "        \"\",\n",
    "        \"/\",\n",
    "        \"/<id>\",\n",
    "        \"/<id><path>\"\n",
    "    ],\n",
    "    \"<id>\": [\n",
    "        \"folder\"\n",
    "    ],\n",
    "    \"<query>\": [\n",
    "        \"\",\n",
    "        \"?<params>\"\n",
    "    ],\n",
    "    \"<params>\": [\n",
    "        \"<param>\",\n",
    "        \"<param>&<params>\"\n",
    "    ],\n",
    "    \"<param>\": [\n",
    "        \"<key>=<value>\"\n",
    "    ],\n",
    "    \"<key>\": [\n",
    "        \"key1\",\n",
    "        \"key2\",\n",
    "        \"key3\",\n",
    "        \"key4\"\n",
    "    ],\n",
    "    \"<value>\": [\n",
    "        \"value1\",\n",
    "        \"value2\",\n",
    "        \"value3\",\n",
    "        \"value4\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grammar Miner Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarCoverageFuzzer import GrammarCoverageFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment:\n",
    "    def __init__(self, reference_grammar, target, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.grammar = reference_grammar\n",
    "        self.target_program = target\n",
    "        self.max_no_samples = 1000\n",
    "        \n",
    "        self.gcf = GrammarCoverageFuzzer(self.grammar)\n",
    "        self.generated_samples = self.generate_sample_inputs() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files', [])\n",
    "        self.methods = kwargs.get('methods', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def generate_sample_inputs(self):\n",
    "        return [self.gcf.fuzz() for _ in range(self.max_no_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarMiner import recover_grammar, recover_grammar_with_taints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def mine_with_taint(self):\n",
    "        grammar_from_taint = recover_grammar_with_taints(\n",
    "            self.target_program,\n",
    "            self.generated_samples,\n",
    "            files=self.files,\n",
    "            methods=self.methods)\n",
    "\n",
    "        return grammar_from_taint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def mine_with_substr_search(self):\n",
    "        grammar_from_substr = recover_grammar(self.target_program,\n",
    "                                              self.generated_samples,\n",
    "                                              files=self.files,\n",
    "                                              methods=self.methods)\n",
    "        return grammar_from_substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ex = GrammarMinerExperiment(REFERENCE_URL_GRAMMAR,\n",
    "                            urlparse,\n",
    "                            methods=['urlparse'],\n",
    "                            files=['urllib/parse.py'])\n",
    "\n",
    "grammar_from_taint = ex.mine_with_taint()\n",
    "grammar_from_str = ex.mine_with_substr_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grammar Miner Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator:\n",
    "    def __init__(self, target, r_grammar):\n",
    "        self.max_no_inputs = 1000\n",
    "        self.target_program = target\n",
    "        self.grammar = r_grammar\n",
    "\n",
    "        self.gcf = self.create_gcf_instance(self.grammar)\n",
    "        self.samples = [self.gcf.fuzz() for i in range(self.max_no_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator(GrammarMinerEvaluator):\n",
    "    def create_gcf_instance(self, grammar):\n",
    "        return GrammarCoverageFuzzer(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator(GrammarMinerEvaluator):\n",
    "    def url_parser_accuracy_test(self, mined_grammar):\n",
    "        gcf = self.create_gcf_instance(mined_grammar)\n",
    "        schemes = ['ftps', 'http', 'https', 'ftp']\n",
    "        rejected = []\n",
    "\n",
    "        for i in range(self.max_no_inputs):\n",
    "            s = gcf.fuzz()\n",
    "            parsed_url = urlparse(s)\n",
    "            if parsed_url.scheme not in schemes or not bool(parsed_url.netloc):\n",
    "                rejected.append(s)\n",
    "        return (((self.max_no_inputs - len(rejected)) / self.max_no_inputs) *\n",
    "                100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from Parser import EarleyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator(GrammarMinerEvaluator):\n",
    "    def completeness_test(self, mined_grammar):\n",
    "        rejected = []\n",
    "        parser = EarleyParser(mined_grammar)\n",
    "        for url in self.samples:\n",
    "            try:\n",
    "                tree, *_ = parser.parse(url)\n",
    "            except SyntaxError:\n",
    "                rejected.append(url)\n",
    "        return (((self.max_no_inputs - len(rejected)) / self.max_no_inputs) *\n",
    "                100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "ev = GrammarMinerEvaluator(urlparse, REFERENCE_URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "taint_accuracy = ev.url_parser_accuracy_test(grammar_from_taint)\n",
    "substr_search_accuracy = ev.url_parser_accuracy_test(grammar_from_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "taint_completeness = ev.completeness_test(grammar_from_taint)\n",
    "substr_search_completeness = ev.completeness_test(grammar_from_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Grammar_For_String_Inclusion'] = (substr_search_accuracy, substr_search_completeness)\n",
    "results['Grammar_From_Taint'] = (taint_accuracy, taint_completeness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MicroJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': ['<raw_decode@343:s>'],\n",
       " '<raw_decode@343:s>': ['{\"name\": \"<decode@337:obj.name>\"}'],\n",
       " '<decode@337:obj.name>': ['John']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js = ['{\"name\": \"John\"}']\n",
    "recover_grammar(json.loads, js, files=['__init__.py', 'decoder.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_table(keys, a, c, title):\n",
    "    keys = [k for k in keys if k in a and k in c and a[k] and c[k]]\n",
    "    tbl = ['<tr>%s</tr>' % ''.join([\"<th>%s</th>\" % k for k in ['<b>%s</b>' % title, 'Accuracy (%)', 'Completeness (%)']])]\n",
    "    for k in keys:\n",
    "        h_c = \"<td>%s</td>\" % k\n",
    "        a_c = \"<td>%s</td>\" % a.get(k, ('', 0))[0]\n",
    "        m_c = \"<td>%s</td>\" % c.get(k, ('', 0))[1]\n",
    "        tbl.append('<tr>%s</tr>' % ''.join([h_c, a_c, m_c]))\n",
    "    return display(HTML('<table>%s</table>' % '\\n'.join(tbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th><b>Grammar Mining Techniques</b></th><th>Accuracy (%)</th><th>Completeness (%)</th></tr>\n",
       "<tr><td>Grammar_For_String_Inclusion</td><td>100.0</td><td>60.8</td></tr>\n",
       "<tr><td>Grammar_From_Taint</td><td>100.0</td><td>60.8</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_table(results.keys(), results, results, 'Grammar Mining Techniques')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In the experiment demonstrated above, the generated grammar both techniques proves to be accurate, out of 1000 urls it produces, all were valid urls which are been accepted by the test subject. Also, in terms of completeness, the grammars produced from both techniques could only parse about 60% (which is 608 urls out of 1000) of the samples generated by the reference grammar this is as a result of the grammar being too specific which means it could only parse similar strings which it can produce itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "401px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
