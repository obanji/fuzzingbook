{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grammar Miner Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import fuzzingbook_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation Setup\n",
    "\n",
    "The evaluation of mining input grammar from string inclusion check and grammar mining from dynamic taints are based on 2 question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "Our first question concerns the accuracy of the generated grammars which means, does our mined grammars from both techniques represent strings that would be rejected by our target program? In order to answer this question, we use the grammars produced by the two techniques as *producers*. that is, we start with the start symbol and continuously expand nonterminals according to grammar rules, then the resulting string would be fed into the target program which would either accept or reject it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Completeness\n",
    "\n",
    "The next question concerns the completeness of the generated grammars which baically means to what extent does the grammar not contain strings that actually would be accepted by the test subject? In order to verify this, we used a reference grammar as a producer which would create arbitrary strings which would then be parsed by the generated grammars. \n",
    "A 100% completeness indicates that the mined grammar holds all inputs of the reference grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation Subject\n",
    "\n",
    "The evluation subject in this presentation will be based on;\n",
    "1. Python url parser [urllib/parse.py](https://github.com/python/cpython/blob/3.7/Lib/urllib/parse.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reference Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [],
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "REFERENCE_URL_GRAMMAR = {\n",
    "    \"<start>\" : [\n",
    "        \"<url>\"\n",
    "    ],\n",
    "    \"<url>\" : [\n",
    "      \"<scheme>://<authority><path><query>\"  \n",
    "    ],\n",
    "    \"<scheme>\": [\n",
    "        \"http\",\n",
    "        \"https\",\n",
    "        \"ftp\",\n",
    "        \"ftps\"      \n",
    "    ],\n",
    "    \"<authority>\": [\n",
    "        \"<host>\",\n",
    "        \"<host>:<port>\",\n",
    "        \"<userinfo>@<host>\",\n",
    "        \"<userinfo>@<host>:<port>\"\n",
    "    ],\n",
    "    \"<user>\": [\n",
    "        \"user1\",\n",
    "        \"user2\",\n",
    "        \"user3\",\n",
    "        \"user4\",\n",
    "        \"user5\"\n",
    "    ],\n",
    "    \"<pass>\": [\n",
    "        \"pass1\",\n",
    "        \"pass2\",\n",
    "        \"pass3\",\n",
    "        \"pass4\",\n",
    "        \"pass5\"\n",
    "    ],\n",
    "    \"<host>\": [\n",
    "        \"host1\",\n",
    "        \"host2\",\n",
    "        \"host3\",\n",
    "        \"host4\",\n",
    "        \"host5\"\n",
    "    ],\n",
    "    \"<port>\": [\n",
    "        \"<nat>\"\n",
    "    ],\n",
    "    \"<nat>\": [\n",
    "        \"10\",\n",
    "        \"20\",\n",
    "        \"30\",\n",
    "        \"40\",\n",
    "        \"50\"\n",
    "    ],\n",
    "    \"<userinfo>\": [\n",
    "        \"<user>:<pass>\"\n",
    "    ],\n",
    "    \"<path>\": [\n",
    "        \"\",\n",
    "        \"/\",\n",
    "        \"/<id>\",\n",
    "        \"/<id><path>\"\n",
    "    ],\n",
    "    \"<id>\": [\n",
    "        \"folder\"\n",
    "    ],\n",
    "    \"<query>\": [\n",
    "        \"\",\n",
    "        \"?<params>\"\n",
    "    ],\n",
    "    \"<params>\": [\n",
    "        \"<param>\",\n",
    "        \"<param>&<params>\"\n",
    "    ],\n",
    "    \"<param>\": [\n",
    "        \"<key>=<value>\"\n",
    "    ],\n",
    "    \"<key>\": [\n",
    "        \"key1\",\n",
    "        \"key2\",\n",
    "        \"key3\",\n",
    "        \"key4\"\n",
    "    ],\n",
    "    \"<value>\": [\n",
    "        \"value1\",\n",
    "        \"value2\",\n",
    "        \"value3\",\n",
    "        \"value4\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grammar Miner Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarCoverageFuzzer import GrammarCoverageFuzzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment:\n",
    "    def __init__(self, reference_grammar, target, **kwargs):\n",
    "        self.options(kwargs)\n",
    "        self.grammar = reference_grammar\n",
    "        self.target_program = target\n",
    "        self.max_no_samples = 1000\n",
    "        \n",
    "        self.gcf = GrammarCoverageFuzzer(self.grammar)\n",
    "        self.generated_samples = self.generate_sample_inputs() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def options(self, kwargs):\n",
    "        self.files = kwargs.get('files', [])\n",
    "        self.methods = kwargs.get('methods', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def generate_sample_inputs(self):\n",
    "        return [self.gcf.fuzz() for _ in range(self.max_no_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarMiner import recover_grammar, recover_grammar_with_taints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def mine_with_taint(self):\n",
    "        grammar_from_taint = recover_grammar_with_taints(self.target_program,\n",
    "                                                         self.generated_samples,\n",
    "                                                         files=self.files,\n",
    "                                                         methods=self.methods)\n",
    "        return grammar_from_taint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerExperiment(GrammarMinerExperiment):\n",
    "    def mine_with_substr_search(self):\n",
    "        grammar_from_substr = recover_grammar(self.target_program,\n",
    "                                              self.generated_samples,\n",
    "                                              files=self.files,\n",
    "                                              methods=self.methods)\n",
    "        return grammar_from_substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ex = GrammarMinerExperiment(REFERENCE_URL_GRAMMAR,\n",
    "                            urlparse,\n",
    "                            methods=['urlparse'],\n",
    "                            files=['urllib/parse.py'])\n",
    "\n",
    "grammar_from_taint = ex.mine_with_taint()\n",
    "grammar_from_str = ex.mine_with_substr_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grammar Miner Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator:\n",
    "    def __init__(self, target, r_grammar):\n",
    "        self.max_no_inputs = 1000\n",
    "        self.target_program = target\n",
    "        self.grammar = r_grammar\n",
    "\n",
    "        self.gcf = self.create_gcf_instance(self.grammar)\n",
    "        self.samples = [self.gcf.fuzz() for i in range(self.max_no_inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator(GrammarMinerEvaluator):\n",
    "    def create_gcf_instance(self, grammar):\n",
    "        return GrammarCoverageFuzzer(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator(GrammarMinerEvaluator):\n",
    "    def url_parser_accuracy_test(self, mined_grammar):\n",
    "        gcf = self.create_gcf_instance(mined_grammar)\n",
    "        schemes = ['ftps', 'http', 'https', 'ftp']\n",
    "        rejected = []\n",
    "\n",
    "        for i in range(self.max_no_inputs):\n",
    "            s = gcf.fuzz()\n",
    "            parsed_url = urlparse(s)\n",
    "            if parsed_url.scheme not in schemes or not bool(parsed_url.netloc):\n",
    "                rejected.append(s)\n",
    "        return (((self.max_no_inputs - len(rejected)) / self.max_no_inputs) *\n",
    "                100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from Parser import EarleyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GrammarMinerEvaluator(GrammarMinerEvaluator):\n",
    "    def completeness_test(self, mined_grammar):\n",
    "        rejected = []\n",
    "        parser = EarleyParser(mined_grammar)\n",
    "        for url in self.samples:\n",
    "            try:\n",
    "                tree, *_ = parser.parse(url)\n",
    "            except SyntaxError:\n",
    "                rejected.append(url)\n",
    "        return (((self.max_no_inputs - len(rejected)) / self.max_no_inputs) *\n",
    "                100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "ev = GrammarMinerEvaluator(urlparse, REFERENCE_URL_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "taint_accuracy = ev.url_parser_accuracy_test(grammar_from_taint)\n",
    "substr_search_accuracy = ev.url_parser_accuracy_test(grammar_from_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "taint_completeness = ev.completeness_test(grammar_from_taint)\n",
    "substr_search_completeness = ev.completeness_test(grammar_from_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Grammar_For_String_Inclusion'] = (substr_search_accuracy, substr_search_completeness)\n",
    "results['Grammar_From_Taint'] = (taint_accuracy, taint_completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GrammarMiner import TaintedScopedGrammarMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedTreeMiner(ScopeTreeMiner):\n",
    "    def insert_into_tree(self, my_tree, pair):\n",
    "        var, values, my_scope = my_tree\n",
    "        (nt_var, nt_seq), (v, v_scope) = pair\n",
    "        applied = False\n",
    "        for i, value_ in enumerate(values):\n",
    "            key, arr, scope = value_\n",
    "            self.log(2, \"-> [%d] %s\" % (i, repr(value_)))\n",
    "            if is_nonterminal(key):\n",
    "                applied = self.insert_into_tree(value_, pair)\n",
    "                if applied:\n",
    "                    break\n",
    "            else:\n",
    "                if v_scope != scope:\n",
    "                    if nt_seq > scope:\n",
    "                        continue\n",
    "                if not v or all(t for t in v.origin if t not in key.origin):\n",
    "                    continue  \n",
    "                new_v = ''.join(key[t] for t in v.origin)\n",
    "                \n",
    "                prefix_k_suffix = [\n",
    "                    (nt_var, [(new_v, [], nt_seq)],\n",
    "                     scope) if i == 1 else (e, [], scope)\n",
    "                    for i, e in enumerate(key.partition(new_v))\n",
    "                    if e\n",
    "                ]\n",
    "\n",
    "                del values[i]\n",
    "                for j, rep in enumerate(prefix_k_suffix):\n",
    "                    values.insert(j + i, rep)\n",
    "\n",
    "                applied = True\n",
    "                self.log(2, \" > %s\" % (repr([i[0] for i in prefix_k_suffix])))\n",
    "                break\n",
    "        return applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaintedScopedGrammarMiner(TaintedScopedGrammarMiner):\n",
    "    def create_tree_miner(self, *args):\n",
    "        return TaintedTreeMiner(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def show_table(keys, a, c, title):\n",
    "    keys = [k for k in keys if k in a and k in c and a[k] and c[k]]\n",
    "    tbl = ['<tr>%s</tr>' % ''.join([\"<th>%s</th>\" % k for k in ['<b>%s</b>' % title, 'Accuracy (%)', 'Completeness (%)']])]\n",
    "    for k in keys:\n",
    "        h_c = \"<td>%s</td>\" % k\n",
    "        a_c = \"<td>%s</td>\" % a.get(k, ('', 0))[0]\n",
    "        m_c = \"<td>%s</td>\" % c.get(k, ('', 0))[1]\n",
    "        tbl.append('<tr>%s</tr>' % ''.join([h_c, a_c, m_c]))\n",
    "    return display(HTML('<table>%s</table>' % '\\n'.join(tbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th><b>Grammar Mining Techniques</b></th><th>Accuracy (%)</th><th>Completeness (%)</th></tr>\n",
       "<tr><td>Grammar_For_String_Inclusion</td><td>100.0</td><td>64.9</td></tr>\n",
       "<tr><td>Grammar_From_Taint</td><td>100.0</td><td>64.9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_table(results.keys(), results, results, 'Grammar Mining Techniques')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "In the experiment demonstrated above, the generated grammar from string inclusion proves to be more accurate, out of 1000 strings it produces, all were valid strings which are been accepted by the test subject. Also, in terms of completeness, the grammar produced from string inclusion could only parse about 60% of the samples generated by the reference grammar this is as a result of the grammar being specific.\n",
    "\n",
    "Also the grammar generated from dynamic taints proves to be less accurate with about 74% valid inputs out of 1000 strings which it generates. This was as a result of a bug found in the class `ScopeTreeMiner` which i will explain further below. In terms of completeness, it could only parse about 60% of the strings generated by the reference grammar as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Taking a closer look at the strings produced by the generated grammar from taint, some of these string were been composed wrongly. Let's take a look at an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from GrammarMiner import Tracer, TaintedScopeTracker, ScopeTreeMiner, ostr, display_tree, lr_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urlparse[1]:url@361:1 = ('ftp://user4:pass1@host4/?key4=value3', ('<start>', 0))\n",
      "urlparse[1]:url@361:2 = ('ftp://user4:pass1@host4/?key4=value3', ('urlparse', 1))\n",
      "urlparse[1]:url@369:3 = ('/', ('urlparse', 1))\n",
      "urlparse[1]:scheme@369:1 = ('ftp', ('urlparse', 1))\n",
      "urlparse[1]:netloc@369:1 = ('user4:pass1@host4', ('urlparse', 1))\n",
      "urlparse[1]:query@369:1 = ('key4=value3', ('urlparse', 1))\n"
     ]
    }
   ],
   "source": [
    "inputstr = ex.generated_samples[2]\n",
    "with Tracer(ostr('ftp://user4:pass1@host4/?key4=value3'), files=['urllib/parse.py'],methods=['urlparse']) as tracer:\n",
    "    urlparse(tracer.my_input)\n",
    "\n",
    "sm = TaintedScopeTracker(tracer.my_input, tracer.trace)\n",
    "dt = ScopeTreeMiner(tracer.my_input,sm.my_assignments.defined_vars(formatted=False))\n",
    "for k, v in sm.my_assignments.seq_vars().items():\n",
    "    print(k, '=', repr(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftp://user4:pass1@host4/folder?key4=value2&key3=value4&key2=value3\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"661pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 661.00 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-217 657,-217 657,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"20\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;start&gt;</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"132\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;urlparse@361:url&gt;</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M40.0234,-106.5C47.4165,-106.5 56.2604,-106.5 65.4998,-106.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.6309,-110.0001 75.6309,-106.5 65.6308,-103.0001 65.6309,-110.0001\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"280\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;urlparse@361:url&gt;</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188.3747,-106.5C196.6214,-106.5 205.1782,-106.5 213.6023,-106.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.7821,-110.0001 223.7821,-106.5 213.7821,-103.0001 213.7821,-110.0001\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-201.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;urlparse@369:scheme&gt;</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M286.005,-114.0712C299.5002,-130.5408 334.0322,-169.7266 372,-189.5 375.9362,-191.55 380.1327,-193.3395 384.4393,-194.9014\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"383.3937,-198.2417 393.9851,-197.9698 385.5359,-191.5775 383.3937,-198.2417\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-168.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">:</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M291.42,-114.0394C308.3476,-124.8994 341.3996,-144.9103 372,-156.5 391.3043,-163.8113 414.9413,-168.3857 429.0803,-170.687\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"428.8668,-174.1939 439.2746,-172.2121 429.9026,-167.271 428.8668,-174.1939\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-135.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;urlparse@369:url&gt;</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.0514,-114.0709C340.1327,-118.7872 370.0305,-124.8963 394.7364,-129.9446\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"394.1228,-133.3915 404.621,-131.9644 395.5242,-126.5332 394.1228,-133.3915\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">/</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M336.0316,-106.5C369.6232,-106.5 409.5308,-106.5 429.236,-106.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"429.4818,-110.0001 439.4818,-106.5 429.4818,-103.0001 429.4818,-110.0001\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;urlparse@369:netloc&gt;</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M317.0514,-98.9291C340.1327,-94.2128 370.0305,-88.1037 394.7364,-83.0554\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"395.5242,-86.4668 404.621,-81.0356 394.1228,-79.6085 395.5242,-86.4668\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">/?</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M292.0366,-98.8245C309.1834,-88.1895 341.9063,-68.9872 372,-57.5 390.1328,-50.5785 412.0216,-45.7731 426.3264,-43.0791\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"427.0726,-46.5015 436.3098,-41.3127 425.8529,-39.6086 427.0726,-46.5015\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"441.5\" y=\"-3.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">&lt;urlparse@369:query&gt;</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M286.2529,-98.8152C299.9734,-82.4842 334.5011,-44.2106 372,-24.5 376.6232,-22.0699 381.6025,-19.9795 386.6964,-18.1827\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"388.0806,-21.4164 396.5697,-15.0772 385.9803,-14.739 388.0806,-21.4164\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"600\" y=\"-201.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ftp</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M511.0204,-205.5C536.7015,-205.5 563.7665,-205.5 581.2076,-205.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"581.6095,-209.0001 591.6094,-205.5 581.6094,-202.0001 581.6095,-209.0001\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"600\" y=\"-135.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">/</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M497.8275,-139.5C530.348,-139.5 568.5032,-139.5 587.6773,-139.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"587.7765,-143.0001 597.7764,-139.5 587.7764,-136.0001 587.7765,-143.0001\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"600\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">user4:pass1@host4</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M506.8831,-73.5C516.7563,-73.5 526.9259,-73.5 536.7529,-73.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"536.843,-77.0001 546.8429,-73.5 536.8429,-70.0001 536.843,-77.0001\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"600\" y=\"-3.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">key4=value3</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M505.5111,-7.5C521.8461,-7.5 539.0788,-7.5 554.2899,-7.5\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"554.4619,-11.0001 564.4619,-7.5 554.4619,-4.0001 554.4619,-11.0001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa040a6f860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(inputstr)\n",
    "display(display_tree(dt.tree, graph_attr=lr_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome this problem, we would need to have a class `TaintedTreeMiner` which would extend the `ScopeTreeMiner` in order to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "401px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
